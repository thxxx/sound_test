{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9acb54-b7e8-4ad7-8bf9-480a1cd512d9",
   "metadata": {},
   "source": [
    "### If"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d46ea6-44fe-4a34-942c-79390492bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 각기 다른 csv에 저장되어 있다면 우선 하나로 합치기\n",
    "import pandas as pd\n",
    "\n",
    "total_csv_path = \"\"\n",
    "\n",
    "csvs_to_combine = [\n",
    "    \"artlist_audios.csv\",\n",
    "    \"boom_ui_sounds.csv\",\n",
    "    \"epidemic_audios.csv\",\n",
    "    \"outsourced_sfx_data.csv\",\n",
    "    \"roblox_audios.csv\",\n",
    "    \"zapsplat_audios.csv\"\n",
    "]\n",
    "\n",
    "# Combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(\"./data_folder/\"+f) for f in csvs_to_combine])\n",
    "\n",
    "# Export to csv\n",
    "combined_csv.to_csv(total_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc46187-21f7-463d-be38-7a0ccf4fba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 데이터가 하나의 csv 파일 안에 들어있다고 가정\n",
    "# attr은 audio_path, caption, duration\n",
    "# 우선 eval은 그대로 두기 위해서 train과 eval로 분리\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "total_csv_path = \"\"\n",
    "\n",
    "df = pd.read_csv(total_csv_path)\n",
    "df_sample_90 = df.sample(frac=0.9)\n",
    "df_sample_90.to_csv('train_total_mixed_csv.csv', index=False)\n",
    "df_sample_10 = df.drop(df_sample_90.index)\n",
    "df_sample_10.to_csv('eval_total_mixed_csv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e8e69d-adda-4a27-bb0a-ecaf97816415",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c3fa08-80e0-4ebd-8875-09ecfb2c20af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4437/659662912.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "100%|██████████| 323581/323581 [00:17<00:00, 18220.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 길이 :  323581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train만 읽어서 augment 하기\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import random\n",
    "\n",
    "total_train_data = pd.read_csv(\"/workspace/sound_test/csv_files/total_dataset_with_zapsplat_caption.csv\")\n",
    "\n",
    "datas = []\n",
    "for i in tqdm(range(len(total_train_data))):\n",
    "    row = total_train_data.iloc[i]\n",
    "    datas.append({\n",
    "        \"audio_path\":row['audio_path'],\n",
    "        \"caption\":row['caption'],\n",
    "        \"duration\":row['duration']\n",
    "    })\n",
    "print(\"데이터 길이 : \", len(datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adeb26d7-101e-4229-ba48-408e14a90cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리 내용\n",
    "# 1. 뒤에 문장이 부자연스럽게 끊기는건 제거, 2. 중복 문장 제거\n",
    "def pre_process_description(text):\n",
    "    text = text.strip()\n",
    "    caps = text.split(\".\")\n",
    "    if len(caps) == 1:\n",
    "        return text\n",
    "    if len(caps) != len(set(caps)):\n",
    "        new_caps = []\n",
    "        for c in caps:\n",
    "            if c not in new_caps:\n",
    "                new_caps.append(c)\n",
    "        caps = new_caps\n",
    "    processed_text = \".\".join(caps[:-1])\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0717d-757a-4887-b597-60a0bab05506",
   "metadata": {},
   "source": [
    "### To mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "225d8d0c-2b39-49fe-b00f-8e86252ae527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 사운드 개수 :  323581\n",
      "3초 이하 사운드 개수 :  150726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150726it [00:00, 346628.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어그멘트 된 수 :  37263\n"
     ]
    }
   ],
   "source": [
    "mixed_csv_path = \"mixed_under3s.csv\"\n",
    "\n",
    "under_3seconds = [d for d in datas if d['duration']<=3]\n",
    "\n",
    "print(\"전체 사운드 개수 : \", len(datas))\n",
    "print(\"3초 이하 사운드 개수 : \", len(under_3seconds))\n",
    "\n",
    "def mix_caption(cap1, cap2):\n",
    "    return cap1 + \", \" + cap2\n",
    "\n",
    "# 여기선 그냥 정보만 저장. 실제로 합쳐서 쓰는건 DataLoader 단에서\n",
    "rows = []\n",
    "for idx, data in tqdm(enumerate(under_3seconds)):\n",
    "    # 전체의 N%만 남기기\n",
    "    N=25\n",
    "    rand_value = random.randint(0,100)\n",
    "    if rand_value>=N:\n",
    "        continue\n",
    "    \n",
    "    random_idx = idx # 어떤거랑 합칠지 선택\n",
    "    while random_idx == idx:\n",
    "        random_idx = random.randint(0, len(under_3seconds)-1)\n",
    "\n",
    "    added_audio_path = under_3seconds[random_idx][\"audio_path\"]\n",
    "    added_caption = pre_process_description(under_3seconds[random_idx][\"caption\"])\n",
    "    mixed_caption = mix_caption(pre_process_description(data[\"caption\"]), added_caption)\n",
    "\n",
    "    row = [data[\"audio_path\"], data[\"caption\"], data[\"duration\"], added_audio_path, added_caption, mixed_caption]\n",
    "    rows.append(row)\n",
    "\n",
    "print('어그멘트 된 수 : ', len(rows))\n",
    "rows_for_save = [[\"audio_path\", \"caption\", \"duration\", \"added_audio_path\", \"added_caption\", \"mixed_caption\"]]+rows\n",
    "\n",
    "with open(mixed_csv_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows_for_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eacc41c-173b-4728-a2a4-c299db7b77ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 길이 :  356020\n"
     ]
    }
   ],
   "source": [
    "# 위에서 만든 augment data를 다시 원본에 합쳐서, 증강된 데이터세트 만들기\n",
    "csvs_to_combine = [\n",
    "    \"/workspace/sound_test/csv_files/train_dataset_with_zapsplat_with_caption.csv\",\n",
    "    mixed_csv_path\n",
    "]\n",
    "\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in csvs_to_combine])\n",
    "print(\"총 길이 : \", len(combined_csv))\n",
    "combined_csv.to_csv(\"train_dataset_with_zapsplat_with_caption_mixed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a01090-ff1e-4994-86fb-1fa7cf28b421",
   "metadata": {},
   "source": [
    "### To concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a2ec1d-f42d-459f-8e75-555b04e0eb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 사운드 개수 :  323581\n",
      "1.5초 이하 사운드 개수 :  102483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102483it [00:00, 296326.20it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "concated_csv_path = \"concat_under15s.csv\"\n",
    "\n",
    "under_15seconds = [d for d in datas if d['duration']<=1.5]\n",
    "\n",
    "print(\"전체 사운드 개수 : \", len(datas))\n",
    "print(\"1.5초 이하 사운드 개수 : \", len(under_15seconds))\n",
    "\n",
    "def mix_caption(cap1, cap2):\n",
    "    concat_cap = \"\"\n",
    "    rv = random.randint(0,2)\n",
    "    if rv == 0:\n",
    "        concat_cap = cap1+\" followed by \"+cap2\n",
    "    if rv == 1:\n",
    "        concat_cap = cap1+\", and then \"+cap2\n",
    "    if rv == 2:\n",
    "        concat_cap = cap2+\" after \"+cap1\n",
    "    return concat_cap\n",
    "\n",
    "# 여기선 그냥 정보만 저장. 실제로 합쳐서 쓰는건 DataLoader 단에서\n",
    "rows = []\n",
    "for idx, data in tqdm(enumerate(under_15seconds)):\n",
    "    # 전체의 N%만 남기기\n",
    "    N=25\n",
    "    rand_value = random.randint(0,100)\n",
    "    if rand_value>=N:\n",
    "        if rand_value<35:\n",
    "            row = [data[\"audio_path\"], data[\"caption\"], data[\"duration\"], data[\"audio_path\"], data[\"caption\"], data[\"caption\"]+\", twice\"]\n",
    "            rows.append(row)\n",
    "        continue\n",
    "    \n",
    "    random_idx = idx # 어떤거랑 합칠지 선택\n",
    "    while random_idx == idx:\n",
    "        random_idx = random.randint(0, len(under_15seconds)-1)\n",
    "\n",
    "    added_audio_path = under_15seconds[random_idx][\"audio_path\"]\n",
    "    added_caption = pre_process_description(under_15seconds[random_idx][\"caption\"])\n",
    "    mixed_caption = mix_caption(pre_process_description(data[\"caption\"]), added_caption)\n",
    "\n",
    "    row = [data[\"audio_path\"], data[\"caption\"], data[\"duration\"], added_audio_path, added_caption, mixed_caption]\n",
    "    rows.append(row)\n",
    "\n",
    "rows_for_save = [[\"audio_path\", \"caption\", \"duration\", \"added_audio_path\", \"added_caption\", \"mixed_caption\"]]+rows\n",
    "\n",
    "with open(concated_csv_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows_for_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53516f2-3ed1-455e-bb41-3f63d71ff8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 만든 augment data를 다시 원본에 합쳐서, 증강된 데이터세트 만들기\n",
    "csvs_to_combine = [\n",
    "    \"/workspace/sound_test/csv_files/train_dataset_with_zapsplat_with_caption.csv\",\n",
    "    concated_csv_path\n",
    "]\n",
    "\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in csvs_to_combine])\n",
    "combined_csv.to_csv(\"train_dataset_with_zapsplat_with_caption_concated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422761db-d798-45eb-ad28-03e623701b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c17ef-7718-42b1-930d-09ed67d30cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
